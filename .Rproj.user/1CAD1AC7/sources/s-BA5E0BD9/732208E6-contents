---
title: "Ecommerce"
author: "Daniel Ramos"
date: "24/1/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(formattable)
library(mltools)
library(arules)
library(arulesViz)
```

## Parte 1 Contexto del problema y modelo de datos (30/100)

### 1.Contextualiza a partir de la información del origen de los datos de que disponemos. Qué datos contiene cada uno de los ficheros y para qué nos pueden resultar importantes en nuestro proyecto. Construir el modelo de datos para vuestro problema.

El fichero del cual se extraen los datos es data.csv, el cual contiene la información de las transacciones de un comerciante al por menor de Reino Unido.
El fichero esta compuesto por 8 columnas y más de medio millón de filas.

Las columnas son las siguentes:

- Nº de Factura:
- Código de Stock
- Descripción
- Cantidad
- Fecha de Factura
- Precio por unidad
- ID del comprador
- País

Con los siguientes datos se va a recoger una serie datos como, por ejemplo, el producto estrella, la época del año en que más se vende, el pedido más grande...
Aún asi, hay que destacar que el análisis más importante va a ser un modelo de predicción mediantes series temporales para predecir el stock de este Ecommerce, es bien conocida la importancia del buen manejo del stock para optimizar los recursos de la empresa y obtener el máximo de beneficio posible teniendo siempre la máxima disponibilidad de productos. 

### 2.Realiza la limpieza de datos, si es necesario, y validación de las variables (análisis de valores perdidos, valores nulos, valores aberrantes, datos fuera de rango…)
```{r}
#Cargamos los datos:
data <- read.csv("data.csv")
class(data$InvoiceDate)
#A priori parace que solo tenemos problemas con la fecha de la factura que es leída como un string
data <- data %>%
  mutate(
    ParsedDate = parse_datetime(InvoiceDate, format = "%m/%d/%Y %H:%M")
  )
#Comprobamos que no haya NA en el fichero
anyNA(data) #Tenemos NA
summary(data) #Solo hay NA's en CustomerID

#Borramos todos los precios y cantidades negativas
data <- data %>% 
  mutate(Quantity = replace(Quantity, Quantity<=0, NA),
         UnitPrice = replace(UnitPrice, UnitPrice<=0, NA))
#Borramos los NA
data <- data %>%
  drop_na()

#Sustituimos los NA por 0, son 135080 observaciones que pueden contener información interesante
#data$CustomerID <- ifelse(is.na(data$CustomerID)== TRUE,0,data$CustomerID)
#Si hay duplicados los eliminamos con la función de dplyr
data <- data %>%
  distinct()

#Añadimos una columna con el precio total de cada venta:
data <- data %>% mutate(lineTotal = Quantity * UnitPrice)

#Añadimos una columna con el dia de la semana
data$weekDay <- wday(data$ParsedDate, label=TRUE)
#Como la etiquetas que genera automáticamente son horribles vamos a renombrarlas
levels(data$weekDay) <- c("Dom","Lun","Mar","Mie","Jue","Vie","Sab")

#Añadimos una columna con el mes del año
data$month <- month(data$ParsedDate, label = TRUE)

#Convertimos los paises en un factor
data$Country <- as.factor(data$Country)
```

### 3.Justifica para cada una de las variables de vuestro proyecto el tipo de dato que mejor se ajusta a cada una de ellas: numérico, ordinal, categórico…. Transforma cada variable al tipo adecuado de dato.

- Nº de Factura: Es una variable categórica ordinal, ya que el orden sí que es importante. Se mantendrá esta variable como una cadena de caracteres por una sencilla razón, no todas las facturas son númericas, hay algunas que empiezan por la letra C, que significan una cancelación.

- Código de Stock: Es una variable categórica, ya que tiene un valor finito, pero la mantendremos como un string ya que tiene valores alfanúmericos y son muchos productos diferentes.

- Descripción: Es una variable categórica única para cada producto y la manera más comoda de usarla es mediante caracteres ya que son muchos productos.

- Cantidad: Es una variable númerica y la mantendremos como un entero.

- Fecha de Factura: Es una variable ordinal, ya que el orden es importante y tiene un rango de valores finito, aún asi se ha parseado la varible para que R puede interpretarla en formato fecha.

- Precio por unidad: Es una variable númerica.

- ID del comprador: Esta variable es una variable categorica que representa a cada comprador, pero por comodidad para el análisis la dejaremos como variable númerica.

- País: Variable categórica que representa a cada país y se utiliza un factor.


## Parte 2: Análisis exploratorio (EDA). (30/100)

### En las siguientes preguntas aplica todo lo que hemos visto acerca de la documentación en el EDA: Título de gráficos, etiquetas de los ejes, coloreado con información, leyendas, tablas bien presentadas (knitr)… Establece en dos o tres etapas un Análisis Exploratorio (EDA) global de estos datos que incluya algunos de estos aspectos:

Producto estrella, país donde más se vende, cliente estrella, epoca del año en la que se vende más, cantidad total vendida en ese periodo y "beneficio", número de cancelaciones...

#### Estadísticas generales sobre la cantidad de productos que vendemos:
```{r}
data %>%
  group_by(StockCode) %>%
  summarise(count = n(),
            sum_quantity = sum(Quantity),
            mean_quantity = round(mean(Quantity), 2),
            median_quantity = median(Quantity),
            mode_quantity = unique(Quantity)[which.max(tabulate(match(Quantity, unique(Quantity))))],
            sd_quantity = round(sd(Quantity), 2))
```

#### 10 Productos más vendidos:
```{r}
#Detalle importante a tener en cuenta: El precio de los productos son menores si se compran en grandes cantidades:
data %>%
  group_by(StockCode, UnitPrice) %>%
  summarise(Total = sum(Quantity)) %>% head(10)

#Observamos la cantidad total vendida de cada producto
sales <- data %>%
  group_by(StockCode) %>%
  summarise(Total = sum(Quantity))

#Ordenamos de mayor a menor
sales <- sales[
  with(sales, order(-Total)),
]
sales %>% top_n(10) %>%
  formattable(align = c("l", "c"),
              list(Total = color_bar("lightgrey")),
              col.names = c("Código","Nº Vendido"))
  
```

#### Productos menos vendidos:
```{r}
#Tenemos muchos productos que se han vendido menos de 10 veces
sum(sales$Total < 10) #En concreto 338
#Quizás lo mejor sería eliminar estos productos del Stock
sales[sales$Total < 10,]
```
#### Datos totales:
```{r}
#Total de productos vendidos, total clientes, total dinero ganado, facturas y paises
#Sumamos las columnas de cantidades y beneficio
sums <- data %>% 
  select(Quantity,lineTotal) %>%
  summarise_all(sum)

#Cogemos los valores únicos
unic <- data %>% select(InvoiceNo, StockCode, CustomerID, Country) %>% summarise_all(n_distinct)
#Combinamos los dos dataframes
totalStats <- merge(sums,unic)
totalStats %>% formattable(align = c("c", "c", "c", "c", "c", "c"),
                           col.names = c("Volumen ventas","Beneficio obtenido", "Facturas emitidas","Nº de productos en Stock", "Clientes únicos", "Paises"))

```


#### Dia de la semana que más se vende
```{r}
data %>%
  group_by(weekDay) %>%
  summarise(revenue = sum(lineTotal)) %>%
  ggplot(aes(x = weekDay, y = revenue)) + geom_col(fill='darkblue') + labs(x = 'Dia de la semana', y = 'Beneficio (£)', title = 'Beneficio por dia de la semana')
```

Se observa algo curioso, los jueves son el día que más se vende mientra que los domingos es el dia que menos.

#### Época del año en que más se vende
```{r}
data %>%
  group_by(month) %>%
  summarise(revenue = sum(lineTotal)) %>%
  ggplot(aes(x = month, y = revenue)) + geom_col(fill='darkblue') + labs(x = 'Mes', y = 'Beneficio (£)', title = 'Beneficio por mes')
```

Observamos claramente que en el último cuatrimestre del año se vende mucho más que el resto.

#### Mapa de calor con los países
```{r}
#Mapa regiones vendidas
country <- data %>%
  group_by(Country) %>%
  summarise(SalesVolume = sum(Quantity)) %>%
  rename(region = Country)

country$region <- ifelse(country$region == "United Kingdom", "UK",country$region)
country$region <- ifelse(country$region == "EIRE", "Ireland",country$region)

#Como las ventas en UK son mucho mayores que en el resto de paises aplicamos logaritmos
country <- country %>%
  mutate(logVolume = log(SalesVolume),
         Proportion = (SalesVolume/sum(SalesVolume))*100)

country$Proportion <- round(country$Proportion,2)

world_map <- map_data("world")
salesmap <- full_join(country, world_map, by = "region")
ggplot(salesmap, aes(map_id = region, fill = logVolume))+
  geom_map(map = salesmap,  color = "white")+
  expand_limits(x = salesmap$long, y = salesmap$lat)+
  scale_fill_viridis_c(option = "C")

#Tabla ventas por paises y proporción
country %>%
  select(region,SalesVolume,Proportion) %>%
  arrange(desc(Proportion)) %>%
  formattable(align = c("l", "c", "c"),
              list(SalesVolume = color_bar("lightgrey"),
                   Proportion = 
                     formatter("span", style = ~ style(font.weight = "bold"))),
              col.names = c("País","Volumen Ventas", "Proporción"))




```
Se ha aplicado el logaritmo de las ventas porque como se puede observar en la tablas la mayoría de venta son en el mismo país, Reino Unido. Luego se vende en el resto de paises en menor medida pero se puede ver una clara diferencia una vez aplicados los logaritmos.
### Gráficos con ggplot2 de las v.a. discretas, continuas
### Gráficos de dos variables segmentando una en función de otras, que tenga sentido. Por ejemplo continua versus factor.
### Tablas de resumen de estadísticos globales.
### Tablas de resumen de estadísticos por grupos.
### Ampliación de alguna técnica de inferencia estadística.


## Parte 3: Aprendizaje estadístico (Machine Learning) (40/100)
En esta última parte aplica algunas de las técnicas de Machine Learning que hemos visto.

En cada caso de machine learning, si es necesario, divídelos en conjuntos de datos de training y de testing.

Sobre todo desde el punto de vista de la parte de la tecnología de aplicación.

#### Reducción de la dimensión del dataset.

En el dataset hay datos que no son utiles a la hora de explicar nada. Por tanto vamos seleccionar solo variables relevantes:
```{r}
# #Seleccionamos las columnas que nos interesan
# r_data <- data %>%
#   select(CustomerID, Quantity, UnitPrice, Country)
# onehot <- one_hot(as.data.table(r_data))
# pr.out <- prcomp(onehot[,-1], scale = TRUE)
# pr.out$rotation
# biplot(pr.out, scale=0)
```



### Para alguna de las variables continuas, aplica al menos dos de los algoritmos de regresión. Se valorará tener el modelo, su explicación, así como una representación gráfica del resultado.
### Para alguna de las variables discretas, aplica al menos dos de los algoritmos de clasificación. Se valorará tener el modelo, su explicación, así como una representación gráfica del resultado.
### Reduce la dimensión de tu dataset con LDA o PCA (puede resultar interesante para reducir el número de variables a 2 o 3 para así representarlo en uno, dos o tres gráficos del plano).
### Crea un clustering por k-means o jerárquico utilizando como entrada resultado de la reducción de la dimensión anterior, para segmentar las observaciones en un número de grupos. Se valorará tener el modelo, su explicación, así como una representación gráfica del resultado.

#### Regresión lineal

```{r}
rl_data <- data %>%
  select()
```


#### Reglas de asociación

Tenemos que tener los datos en un formato en concreto. Necesitamos los clientes en las filas y los productos adquiridos en columnas.
```{r}
a_data <- data %>%
  select(CustomerID, StockCode) %>%
  mutate(StockCode = strsplit(StockCode, ",")) %>% 
    unnest %>% 
    distinct(CustomerID, StockCode) %>% 
    group_by(CustomerID) %>% 
    summarise(StockCode = toString(StockCode))

```

Solo tendremos en cuenta cesta de compra de hasta 100 productos para evitar consumir demasiado espacio de memoria, ya que la mayoría de usuarios compra bastantes menos productos que estos.
```{r}
a_data <- a_data %>% separate(StockCode, as.character(c(1:100)), ",")
#Convertimos en una matrix sparse para ahorrar más memoria
write.csv(a_data[,-1], "DatosTransacciones.csv")
dataset <- read.transactions("DatosTransacciones.csv", header = T, sep = ",", rm.duplicates = T)
```

Ahora que tenemos listos los datos, podemos comenzar a trabajar con las reglas de asociación.
```{r}
summary(dataset)
```
De aquí podemos obtener un par de datos interesantes como que casi la totalidad de la matriz esta vacía, solo un 0.00005% esta ocupada por datos.

Los items (por su nombre de Stock) más vendidos son:
22423, 85123A, 47566, 84879, 22720, (Other), 801, 627, 609, 575, 199410

También podemos observar que 91 cestas de compra contenian sólo 2 items mientras que 780 cestas de compra contenian 101 items.

```{r}
itemFrequencyPlot(dataset, topN = 25)
```

En el gráfico anterior se observan los 25 productos más vendidos.

Comenzamos creando las reglas de asociación:
```{r}
#Entrenamos el algoritmo Apriori
rules = apriori(dataset, list(support = 0.05, confidence = 0.8))
```
Hemos seleccionado un soporte de 0.05, por lo que no tratamos con items que son comprados rara vez, lo que significa que cortamos en el gráfico de frecuencias anterior por ese valor y nos han aparecido 5 reglas. Con el nivel de confianza de 0.8 significa que estas reglas se cumplen en 4 de cada 5 cestas de la compra.

```{r}
inspect(sort(rules, by = "lift"))
```
Como tenemos los items nombrados por su código de stock esto no nos da mucha información, vamos a ver cuales son estos items:
```{r}
data %>%
  select(StockCode, Description) %>%
  filter(StockCode == "22698" | StockCode == "22699"| StockCode == "22697") %>%
  unique()
```
Vemos que se trata de un set de tazas de té con su plato en colores diferentes.
Tiene sentido, ya que la mayoría de compras se hacen desde Reino Unido y allí beben mucho té.

```{r}
#Volvemos a aplicar las reglas de asociación pero con una confianza un poco más baja
rules = apriori(dataset, list(support = 0.05, confidence = 0.6))
inspect(sort(rules, by = "lift")[1:10])
```
Vamos a ver que items nuevos aparecen ahora:
```{r}
data %>%
  select(StockCode, Description) %>%
  filter(StockCode == "22698" | StockCode == "22699"| StockCode == "22697" | StockCode == "22910" | StockCode == "22086") %>%
  unique()
```
Seguimos observando las combinaciones del set de tazas de té de diferentes colores pero ahora también han aparecido cadenas de papel con estilo navideño.
Si compran el set vintage, también compran el estilo de los años 50. Tiene sentido.

Aquí podemos observar las distintas reglas y como se aplican a los casos mencionados anteriormente de manera interactiva:
```{r}
reglas <- sort(rules, by = "lift")[1:10]
plot(reglas, method = "graph", engine = "htmlwidget")
```


